{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9618ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import applications\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acae188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/hubmap segmentation challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8d2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rle(img, size):\n",
    "    pixels = cv2.resize(img,size).T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e86e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_string, size):\n",
    "    rle = np.array(list(map(int, rle_string.split())))\n",
    "    label = np.zeros((size*size), dtype=np.uint8)\n",
    "    for start, end in zip(rle[::2], rle[1::2]):\n",
    "        label[start:start+end] = 1\n",
    "    return label.reshape(size, size).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff90bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSAC_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape, filters, dilation_rates=[6, 12, 18], batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.dilation_rates = dilation_rates\n",
    "        self.batchnorms = []\n",
    "        self.filters = filters\n",
    "        if batchnorm:\n",
    "            self.batchnorms = [tf.keras.layers.BatchNormalization() for _ in dilation_rates]\n",
    "        self.kernel_initializer = tf.keras.initializers.GlorotUniform()\n",
    "        self.kernel_shape = (3, 3, input_shape[-1], filters)\n",
    "        self.kernel = tf.Variable(self.kernel_initializer(self.kernel_shape), trainable=True)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        feature_maps = [tf.nn.conv2d(x, self.kernel, (1, 1), 'SAME', dilations=d) for d in self.dilation_rates]\n",
    "        if len(self.batchnorms) > 0:\n",
    "            for i in range(len(feature_maps)):\n",
    "                feature_maps[i] = self.batchnorms[i](feature_maps[i], training=training)\n",
    "        return sum(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744875a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSAC_pooling(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, batchnorm = False):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.batchnorm = []\n",
    "        if batchnorm:\n",
    "            self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(filters, 1, (1,1))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D(keepdims=True)(x)\n",
    "        x = self.conv_layer(x)\n",
    "        if self.batchnorm != []:\n",
    "            x = self.batchnorm(x)\n",
    "        return tf.image.resize(images=x, size=x.shape[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28c6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSAC_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, input_shape, dilation_rate=[6, 12, 18], batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters, 1, (1, 1))\n",
    "        self.batchnorm = []\n",
    "        if batchnorm:\n",
    "            self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "        self.ksac_layer = KSAC_layer(input_shape, filters, dilation_rate, batchnorm)\n",
    "        self.ksac_pooling = KSAC_pooling(filters, batchnorm)\n",
    "        self.bias = tf.Variable(tf.zeros_initializer()((filters,)), trainable=True, name='bias')\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self.conv1(x)\n",
    "        if self.batchnorm != []:\n",
    "            y = self.batchnorm(y)\n",
    "        return tf.nn.relu(y + self.ksac_layer(x) + self.ksac_pooling(x) + self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9481f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3_Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, out_size, batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.batchnorm = []\n",
    "        if batchnorm:\n",
    "            self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters, 1, (1, 1))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(1, 3, (1, 1), \"SAME\", activation='sigmoid')\n",
    "        self.out_size = out_size\n",
    "\n",
    "    def call(self, x1, x2):\n",
    "        x2 = self.conv1(x2)\n",
    "        x2 = self.batchnorm(x2)\n",
    "        x2 = tf.nn.relu(x2)\n",
    "        x2 = tf.image.resize(images=x2, size=x1.shape[1:-1])\n",
    "        x = tf.concat([x1, x2], axis=-1)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.image.resize(images=x, size=self.out_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0511343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSAC_network(tf.keras.Model):\n",
    "    def __init__(self, input_shape, filters, dilation_rate=[6,12,18], batchnorm=True):\n",
    "        super().__init__()\n",
    "        resnet_backbone = applications.resnet50.ResNet50(\n",
    "            include_top=False,\n",
    "            weights=None,\n",
    "            input_tensor=None,\n",
    "            input_shape=input_shape,\n",
    "            pooling=None,\n",
    "            classes=1000,\n",
    "        )\n",
    "        resnet_backbone = tf.keras.Model(inputs=resnet_backbone.inputs,\n",
    "                                         outputs=[resnet_backbone.get_layer('conv3_block4_out').output,\n",
    "                                                  resnet_backbone.get_layer('conv4_block6_out').output])\n",
    "        #print(resnet_backbone.summary())\n",
    "\n",
    "        x = tf.keras.Input(input_shape)\n",
    "        x1, x2 = resnet_backbone(x)\n",
    "        print(x.shape)\n",
    "        # print(x1.shape, x2.shape)\n",
    "        x2 = KSAC_block(filters, x2.shape, dilation_rate, batchnorm)(x2)\n",
    "        print(x.shape)\n",
    "        logits = DeepLabV3_Decoder(filters, input_shape[:-1])(x1,x2)\n",
    "        self.model = tf.keras.Model(inputs=x, outputs=logits)\n",
    "        self.loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    def compile(self, optimizer, *args, **kwargs):\n",
    "        self.focal_loss_metric = keras.metrics.Mean(name=\"focal_loss\")\n",
    "        self.accuracy_metric = keras.metrics.Mean(name='accuracy')\n",
    "        self.optimizer = optimizer\n",
    "        super(KSAC_network, self).compile(*args, **kwargs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8e1d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512, 512, 3)\n",
      "(None, 512, 512, 3)\n",
      "(None, 512, 512, 3)\n",
      "(None, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "ksac_network_1 = KSAC_network((512,512,3), 128)\n",
    "ksac_network_2 = KSAC_network((512,512,3), 128)\n",
    "ksac_network_1.model.load_weights('models/ksac_network_weights/ksac_model_100.h5')\n",
    "ksac_network_2.model.load_weights('models/ksac_network_weights/ksac_model_2_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd84feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, image):\n",
    "    \"\"\"going to flip the model and infer from all possible angles then find overlapping mask\"\"\"\n",
    "    threshold = 0.2\n",
    "    \n",
    "    logits_normal = model(image)\n",
    "    normal_binarised = (logits_normal.numpy() > threshold).astype(np.uint8)\n",
    "    \n",
    "    logits_horizontal_flip = np.flip(model(np.flip(image, axis=0)), axis=0)\n",
    "    horizontal_binarised = (logits_horizontal_flip.numpy() > threshold).astype(np.uint8)\n",
    "    \n",
    "    logits_vertical_flip = np.flip(model(np.flip(image, axis=1)), axis=1)\n",
    "    vertical_binarised = (logits_vertical_flip.numpy() > threshold).astype(np.uint8)\n",
    "    \n",
    "    total_mask = (normal_binarised+horizontal_binarised+vertical_binarised).astype(np.float32)\n",
    "    #including on the final mask any region which more than one flip agrees on\n",
    "    total_mask = (total_mask > 2.0).astype(np.uint8)\n",
    "    return total_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f495070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_infer(models, image):\n",
    "    total_mask = np.zeros((np.shape(image)[1], np.shape(image)[2],1))\n",
    "    for model in models:\n",
    "        total_mask += infer(model, image).squeeze(0)\n",
    "    total_mask = (total_mask > len(models)/2).astype(np.uint8)\n",
    "    return total_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "45fd114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "358fa83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, data):\n",
    "    output_dict = {'id':[],'rle':[]}\n",
    "    for i in range(0,len(data)):\n",
    "        #print(str(data[i]))\n",
    "        image = (cv2.imread(('test_images/'+str(data[i][0])+'.tiff')))\n",
    "        image = np.expand_dims(cv2.resize((image/255),(512,512)),0)\n",
    "        mask = ensemble_infer(models,image)\n",
    "        #print(data[i][4])\n",
    "        rle = mask_to_rle(mask, (data[i][4],data[i][4]))\n",
    "        output_dict['id'].append(str(data[i][0]))\n",
    "        output_dict['rle'].append(rle)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f77912c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = test([ksac_network_1.model, ksac_network_2.model], test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0d7ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe = pd.DataFrame(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca3f50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe.to_csv('output_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cddf75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow25)",
   "language": "python",
   "name": "tensorflow25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
